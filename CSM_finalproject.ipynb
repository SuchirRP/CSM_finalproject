{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc26d5f-e9a7-4bbb-b391-dae6db3c9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae294d7a-39fa-4e39-bd21-8b9e392b2dd0",
   "metadata": {},
   "source": [
    "# Data Collection and PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25d37a-5899-47f9-8741-53b9aa2606bf",
   "metadata": {},
   "source": [
    "## Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51f4c0a-6898-47d6-a89c-1e13dab2e002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data for IBM:\n",
      "            adj close_ibm   close_ibm    high_ibm     low_ibm    open_ibm  \\\n",
      "Date                                                                        \n",
      "2014-08-01     115.999779  180.831741  183.078400  180.554489  182.122375   \n",
      "2014-08-04     116.300232  181.300186  181.596558  180.305923  181.022949   \n",
      "2014-08-05     114.742554  178.871887  180.879547  178.240921  180.449326   \n",
      "2014-08-06     114.723991  177.791580  178.661575  176.328873  177.208420   \n",
      "2014-08-07     113.693802  176.195023  178.470367  175.506699  178.432129   \n",
      "\n",
      "            volume_ibm  \n",
      "Date                    \n",
      "2014-08-01     5419431  \n",
      "2014-08-04     2223691  \n",
      "2014-08-05     3460063  \n",
      "2014-08-06     4023962  \n",
      "2014-08-07     2833196  \n",
      "Saved IBM data to datasets/IBM_stock.csv\n",
      "\n",
      "Data for AAPL:\n",
      "            adj close_aapl  close_aapl  high_aapl   low_aapl  open_aapl  \\\n",
      "Date                                                                      \n",
      "2014-08-01       21.209679   24.032499  24.155001  23.702499  23.725000   \n",
      "2014-08-04       21.090534   23.897499  24.145000  23.792500  24.092501   \n",
      "2014-08-05       20.986847   23.780001  23.920000  23.590000  23.840000   \n",
      "2014-08-06       20.951538   23.740000  23.870001  23.677500  23.687500   \n",
      "2014-08-07       20.949327   23.620001  23.987499  23.525000  23.732500   \n",
      "\n",
      "            volume_aapl  \n",
      "Date                     \n",
      "2014-08-01    194044000  \n",
      "2014-08-04    159832000  \n",
      "2014-08-05    223732000  \n",
      "2014-08-06    154232000  \n",
      "2014-08-07    186844000  \n",
      "Saved AAPL data to datasets/AAPL_stock.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data for META:\n",
      "            adj close_meta  close_meta  high_meta   low_meta  open_meta  \\\n",
      "Date                                                                      \n",
      "2014-08-01       72.142792   72.360001  73.220001  71.550003  72.220001   \n",
      "2014-08-04       73.289337   73.510002  73.879997  72.360001  72.360001   \n",
      "2014-08-05       72.471802   72.690002  73.589996  72.180000  73.199997   \n",
      "2014-08-06       72.252449   72.470001  73.720001  71.790001  72.019997   \n",
      "2014-08-07       72.950348   73.169998  74.000000  72.699997  73.000000   \n",
      "\n",
      "            volume_meta  \n",
      "Date                     \n",
      "2014-08-01     43535000  \n",
      "2014-08-04     30777000  \n",
      "2014-08-05     34986000  \n",
      "2014-08-06     30986000  \n",
      "2014-08-07     38141000  \n",
      "Saved META data to datasets/META_stock.csv\n",
      "\n",
      "Data for GOOGL:\n",
      "            adj close_googl  close_googl  high_googl  low_googl  open_googl  \\\n",
      "Date                                                                          \n",
      "2014-08-01        28.609159    28.680000   29.171499  28.514999     28.9275   \n",
      "2014-08-04        29.041588    29.113501   29.191000  28.613001     28.8255   \n",
      "2014-08-05        28.586216    28.657000   29.010000  28.515499     28.9690   \n",
      "2014-08-06        28.653551    28.724501   28.931999  28.372499     28.4750   \n",
      "2014-08-07        28.519880    28.590500   28.915501  28.471500     28.8025   \n",
      "\n",
      "            volume_googl  \n",
      "Date                      \n",
      "2014-08-01      44266000  \n",
      "2014-08-04      30388000  \n",
      "2014-08-05      32876000  \n",
      "2014-08-06      26456000  \n",
      "2014-08-07      23260000  \n",
      "Saved GOOGL data to datasets/GOOGL_stock.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd  # Ensure pandas is imported for MultiIndex handling\n",
    "\n",
    "# Define stock tickers and date range\n",
    "start_date = \"2014-08-01\"\n",
    "end_date = \"2016-11-30\"\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "\n",
    "# Create a folder named 'datasets' if it doesn't exist\n",
    "output_folder = \"datasets\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Download data for each stock and save with standardized column names\n",
    "for ticker in tickers:\n",
    "    # Download the stock data\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Check if columns are a MultiIndex and flatten if necessary\n",
    "    if isinstance(stock_data.columns, pd.MultiIndex):\n",
    "        stock_data.columns = ['_'.join(col).strip().lower() for col in stock_data.columns]\n",
    "    else:\n",
    "        stock_data.columns = [col.replace(' ', '_').lower() for col in stock_data.columns]\n",
    "    \n",
    "    # Print the first few rows of the data\n",
    "    print(f\"\\nData for {ticker}:\")\n",
    "    print(stock_data.head())\n",
    "    \n",
    "    # Save to CSV in the 'datasets' folder\n",
    "    file_path = os.path.join(output_folder, f'{ticker}_stock.csv')\n",
    "    stock_data.to_csv(file_path, index=True)\n",
    "\n",
    "    print(f\"Saved {ticker} data to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429628a-c731-48a9-9f8f-33bd61c792bf",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "+ Check for missing values\n",
    "+ identification of outliers and replacement using IQR\n",
    "+ Datatype conversion of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f87c27e-5327-4bb5-996b-779c656052a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning data for IBM:\n",
      "\n",
      "Missing Values:\n",
      "adj close_ibm    0\n",
      "close_ibm        0\n",
      "high_ibm         0\n",
      "low_ibm          0\n",
      "open_ibm         0\n",
      "volume_ibm       0\n",
      "dtype: int64\n",
      "\n",
      "Outliers Detection:\n",
      "adj close_ibm: 12 outliers removed (2.04%)\n",
      "close_ibm: 65 outliers removed (11.05%)\n",
      "high_ibm: 62 outliers removed (10.54%)\n",
      "low_ibm: 62 outliers removed (10.54%)\n",
      "open_ibm: 64 outliers removed (10.88%)\n",
      "volume_ibm: 42 outliers removed (7.14%)\n",
      "\n",
      "Data Type Validation:\n",
      "adj close_ibm    float64\n",
      "close_ibm        float64\n",
      "high_ibm         float64\n",
      "low_ibm          float64\n",
      "open_ibm         float64\n",
      "volume_ibm         int64\n",
      "dtype: object\n",
      "\n",
      "Value Ranges:\n",
      "adj close_ibm: Min = 76.36112976074219, Max = 119.67769622802734\n",
      "close_ibm: Min = 112.66730499267578, Max = 185.46844482421875\n",
      "high_ibm: Min = 114.397705078125, Max = 186.42446899414065\n",
      "low_ibm: Min = 111.7590789794922, Max = 184.69407653808597\n",
      "open_ibm: Min = 113.25048065185548, Max = 185.98471069335935\n",
      "volume_ibm: Min = 1480927, Max = 24493659\n",
      "\n",
      "Cleaned data saved to datasets/IBM_stock_cleaned.csv\n",
      "\n",
      "Cleaning data for AAPL:\n",
      "\n",
      "Missing Values:\n",
      "adj close_aapl    0\n",
      "close_aapl        0\n",
      "high_aapl         0\n",
      "low_aapl          0\n",
      "open_aapl         0\n",
      "volume_aapl       0\n",
      "dtype: int64\n",
      "\n",
      "Outliers Detection:\n",
      "adj close_aapl: 0 outliers removed (0.00%)\n",
      "close_aapl: 0 outliers removed (0.00%)\n",
      "high_aapl: 0 outliers removed (0.00%)\n",
      "low_aapl: 0 outliers removed (0.00%)\n",
      "open_aapl: 0 outliers removed (0.00%)\n",
      "volume_aapl: 25 outliers removed (4.25%)\n",
      "\n",
      "Data Type Validation:\n",
      "adj close_aapl    float64\n",
      "close_aapl        float64\n",
      "high_aapl         float64\n",
      "low_aapl          float64\n",
      "open_aapl         float64\n",
      "volume_aapl         int64\n",
      "dtype: object\n",
      "\n",
      "Value Ranges:\n",
      "adj close_aapl: Min = 20.697269439697266, Max = 29.75617408752441\n",
      "close_aapl: Min = 22.584999084472656, Max = 33.25\n",
      "high_aapl: Min = 22.917499542236328, Max = 33.6349983215332\n",
      "low_aapl: Min = 22.36750030517578, Max = 32.849998474121094\n",
      "open_aapl: Min = 22.5, Max = 33.6150016784668\n",
      "volume_aapl: Min = 45903600, Max = 759385200\n",
      "\n",
      "Cleaned data saved to datasets/AAPL_stock_cleaned.csv\n",
      "\n",
      "Cleaning data for META:\n",
      "\n",
      "Missing Values:\n",
      "adj close_meta    0\n",
      "close_meta        0\n",
      "high_meta         0\n",
      "low_meta          0\n",
      "open_meta         0\n",
      "volume_meta       0\n",
      "dtype: int64\n",
      "\n",
      "Outliers Detection:\n",
      "adj close_meta: 0 outliers removed (0.00%)\n",
      "close_meta: 0 outliers removed (0.00%)\n",
      "high_meta: 0 outliers removed (0.00%)\n",
      "low_meta: 0 outliers removed (0.00%)\n",
      "open_meta: 0 outliers removed (0.00%)\n",
      "volume_meta: 37 outliers removed (6.29%)\n",
      "\n",
      "Data Type Validation:\n",
      "adj close_meta    float64\n",
      "close_meta        float64\n",
      "high_meta         float64\n",
      "low_meta          float64\n",
      "open_meta         float64\n",
      "volume_meta         int64\n",
      "dtype: object\n",
      "\n",
      "Value Ranges:\n",
      "adj close_meta: Min = 72.14279174804688, Max = 132.87989807128906\n",
      "close_meta: Min = 72.36000061035156, Max = 133.27999877929688\n",
      "high_meta: Min = 73.22000122070312, Max = 133.5\n",
      "low_meta: Min = 70.31999969482422, Max = 132.22000122070312\n",
      "open_meta: Min = 70.79000091552734, Max = 133.5\n",
      "volume_meta: Min = 5913100, Max = 107475300\n",
      "\n",
      "Cleaned data saved to datasets/META_stock_cleaned.csv\n",
      "\n",
      "Cleaning data for GOOGL:\n",
      "\n",
      "Missing Values:\n",
      "adj close_googl    0\n",
      "close_googl        0\n",
      "high_googl         0\n",
      "low_googl          0\n",
      "open_googl         0\n",
      "volume_googl       0\n",
      "dtype: int64\n",
      "\n",
      "Outliers Detection:\n",
      "adj close_googl: 0 outliers removed (0.00%)\n",
      "close_googl: 0 outliers removed (0.00%)\n",
      "high_googl: 0 outliers removed (0.00%)\n",
      "low_googl: 0 outliers removed (0.00%)\n",
      "open_googl: 0 outliers removed (0.00%)\n",
      "volume_googl: 44 outliers removed (7.48%)\n",
      "\n",
      "Data Type Validation:\n",
      "adj close_googl    float64\n",
      "close_googl        float64\n",
      "high_googl         float64\n",
      "low_googl          float64\n",
      "open_googl         float64\n",
      "volume_googl         int64\n",
      "dtype: object\n",
      "\n",
      "Value Ranges:\n",
      "adj close_googl: Min = 24.79161262512207, Max = 41.68378448486328\n",
      "close_googl: Min = 24.85300064086914, Max = 41.7869987487793\n",
      "high_googl: Min = 25.013999938964844, Max = 41.95000076293945\n",
      "low_googl: Min = 24.545499801635746, Max = 41.45199966430664\n",
      "open_googl: Min = 24.96199989318848, Max = 41.92499923706055\n",
      "volume_googl: Min = 10412000, Max = 257162000\n",
      "\n",
      "Cleaned data saved to datasets/GOOGL_stock_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the tickers and input/output paths\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "input_folder = \"datasets\"\n",
    "output_folder = \"datasets\"\n",
    "\n",
    "# Function to clean and validate stock data\n",
    "def clean_stock_data(ticker):\n",
    "    # Read the input CSV file\n",
    "    input_path = os.path.join(input_folder, f'{ticker}_stock.csv')\n",
    "    df = pd.read_csv(input_path, parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    print(f\"\\nCleaning data for {ticker}:\")\n",
    "    \n",
    "    # 1. Check for missing values\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # 2. Identify and handle outliers using Interquartile Range (IQR) method\n",
    "    def remove_outliers(column):\n",
    "        Q1 = column.quantile(0.25)\n",
    "        Q3 = column.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        return column[(column >= lower_bound) & (column <= upper_bound)]\n",
    "    \n",
    "    # Apply outlier removal to numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    print(\"\\nOutliers Detection:\")\n",
    "    for col in numeric_columns:\n",
    "        original_count = len(df)\n",
    "        cleaned_series = remove_outliers(df[col])\n",
    "        removed_count = original_count - len(cleaned_series)\n",
    "        print(f\"{col}: {removed_count} outliers removed ({removed_count/original_count*100:.2f}%)\")\n",
    "        df_cleaned.loc[cleaned_series.index, col] = cleaned_series\n",
    "    \n",
    "    # 3. Convert columns to appropriate data types\n",
    "    # Ensure all numeric columns are float\n",
    "    for col in numeric_columns:\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "    \n",
    "    # 4. Additional data validations\n",
    "    print(\"\\nData Type Validation:\")\n",
    "    print(df_cleaned.dtypes)\n",
    "    \n",
    "    # 5. Check for any remaining extreme values\n",
    "    print(\"\\nValue Ranges:\")\n",
    "    for col in numeric_columns:\n",
    "        print(f\"{col}: Min = {df_cleaned[col].min()}, Max = {df_cleaned[col].max()}\")\n",
    "    \n",
    "    # 6. Save cleaned data\n",
    "    output_path = os.path.join(output_folder, f'{ticker}_stock_cleaned.csv')\n",
    "    df_cleaned.to_csv(output_path, index=True)\n",
    "    print(f\"\\nCleaned data saved to {output_path}\")\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Process each stock\n",
    "cleaned_datasets = {}\n",
    "for ticker in tickers:\n",
    "    cleaned_datasets[ticker] = clean_stock_data(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8d53c2-b0c5-4fb6-90c2-f573333a39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IBM':             adj close_ibm   close_ibm    high_ibm     low_ibm    open_ibm  \\\n",
       " Date                                                                        \n",
       " 2014-08-01     115.999779  180.831741  183.078400  180.554489  182.122375   \n",
       " 2014-08-04     116.300232  181.300186  181.596558  180.305923  181.022949   \n",
       " 2014-08-05     114.742554  178.871887  180.879547  178.240921  180.449326   \n",
       " 2014-08-06     114.723991  177.791580  178.661575  176.328873  177.208420   \n",
       " 2014-08-07     113.693802  176.195023  178.470367  175.506699  178.432129   \n",
       " ...                   ...         ...         ...         ...         ...   \n",
       " 2016-11-22     108.312378  155.516251  155.831741  154.827911  155.831741   \n",
       " 2016-11-23     107.852982  154.856598  155.238998  154.263855  154.818359   \n",
       " 2016-11-25     108.625343  155.965576  156.013382  154.713196  154.713196   \n",
       " 2016-11-28     109.544212  157.284897  157.418732  155.544937  156.022949   \n",
       " 2016-11-29     108.884995  156.338425  157.179733  155.860428  156.787766   \n",
       " \n",
       "             volume_ibm  \n",
       " Date                    \n",
       " 2014-08-01     5419431  \n",
       " 2014-08-04     2223691  \n",
       " 2014-08-05     3460063  \n",
       " 2014-08-06     4023962  \n",
       " 2014-08-07     2833196  \n",
       " ...                ...  \n",
       " 2016-11-22     2898257  \n",
       " 2016-11-23     2356324  \n",
       " 2016-11-25     1679144  \n",
       " 2016-11-28     4654072  \n",
       " 2016-11-29     3293017  \n",
       " \n",
       " [588 rows x 6 columns],\n",
       " 'AAPL':             adj close_aapl  close_aapl  high_aapl   low_aapl  open_aapl  \\\n",
       " Date                                                                      \n",
       " 2014-08-01       21.209679   24.032499  24.155001  23.702499  23.725000   \n",
       " 2014-08-04       21.090534   23.897499  24.145000  23.792500  24.092501   \n",
       " 2014-08-05       20.986847   23.780001  23.920000  23.590000  23.840000   \n",
       " 2014-08-06       20.951538   23.740000  23.870001  23.677500  23.687500   \n",
       " 2014-08-07       20.949327   23.620001  23.987499  23.525000  23.732500   \n",
       " ...                    ...         ...        ...        ...        ...   \n",
       " 2016-11-22       25.884813   27.950001  28.105000  27.850000  27.987499   \n",
       " 2016-11-23       25.752846   27.807501  27.877501  27.582500  27.840000   \n",
       " 2016-11-25       25.882500   27.947500  27.967501  27.737499  27.782499   \n",
       " 2016-11-28       25.831560   27.892500  28.117500  27.847500  27.857500   \n",
       " 2016-11-29       25.806093   27.865000  28.007500  27.517500  27.695000   \n",
       " \n",
       "             volume_aapl  \n",
       " Date                     \n",
       " 2014-08-01    194044000  \n",
       " 2014-08-04    159832000  \n",
       " 2014-08-05    223732000  \n",
       " 2014-08-06    154232000  \n",
       " 2014-08-07    186844000  \n",
       " ...                 ...  \n",
       " 2016-11-22    103862000  \n",
       " 2016-11-23    109705600  \n",
       " 2016-11-25     45903600  \n",
       " 2016-11-28    108776000  \n",
       " 2016-11-29    114115200  \n",
       " \n",
       " [588 rows x 6 columns],\n",
       " 'META':             adj close_meta  close_meta   high_meta    low_meta   open_meta  \\\n",
       " Date                                                                         \n",
       " 2014-08-01       72.142792   72.360001   73.220001   71.550003   72.220001   \n",
       " 2014-08-04       73.289337   73.510002   73.879997   72.360001   72.360001   \n",
       " 2014-08-05       72.471802   72.690002   73.589996   72.180000   73.199997   \n",
       " 2014-08-06       72.252449   72.470001   73.720001   71.790001   72.019997   \n",
       " 2014-08-07       72.950348   73.169998   74.000000   72.699997   73.000000   \n",
       " ...                    ...         ...         ...         ...         ...   \n",
       " 2016-11-22      121.105370  121.470001  122.980003  120.900002  122.400002   \n",
       " 2016-11-23      120.477257  120.839996  121.309998  119.940002  121.230003   \n",
       " 2016-11-25      120.018639  120.379997  121.139999  120.070000  121.010002   \n",
       " 2016-11-28      120.048546  120.410004  121.690002  119.820000  120.120003   \n",
       " 2016-11-29      120.507179  120.870003  122.099998  120.400002  120.570000   \n",
       " \n",
       "             volume_meta  \n",
       " Date                     \n",
       " 2014-08-01     43535000  \n",
       " 2014-08-04     30777000  \n",
       " 2014-08-05     34986000  \n",
       " 2014-08-06     30986000  \n",
       " 2014-08-07     38141000  \n",
       " ...                 ...  \n",
       " 2016-11-22     26089200  \n",
       " 2016-11-23     15672100  \n",
       " 2016-11-25      8658600  \n",
       " 2016-11-28     18101300  \n",
       " 2016-11-29     18891000  \n",
       " \n",
       " [588 rows x 6 columns],\n",
       " 'GOOGL':             adj close_googl  close_googl  high_googl  low_googl  open_googl  \\\n",
       " Date                                                                          \n",
       " 2014-08-01        28.609159    28.680000   29.171499  28.514999   28.927500   \n",
       " 2014-08-04        29.041588    29.113501   29.191000  28.613001   28.825500   \n",
       " 2014-08-05        28.586216    28.657000   29.010000  28.515499   28.969000   \n",
       " 2014-08-06        28.653551    28.724501   28.931999  28.372499   28.475000   \n",
       " 2014-08-07        28.519880    28.590500   28.915501  28.471500   28.802500   \n",
       " ...                     ...          ...         ...        ...         ...   \n",
       " 2016-11-22        39.153049    39.250000   39.688499  39.187000   39.449501   \n",
       " 2016-11-23        38.853790    38.950001   39.476002  38.632500   39.476002   \n",
       " 2016-11-25        38.915142    39.011501   39.145000  38.909500   39.130501   \n",
       " 2016-11-28        39.192455    39.289501   39.987000  38.904999   38.917500   \n",
       " 2016-11-29        39.374504    39.472000   39.821999  39.266998   39.418999   \n",
       " \n",
       "             volume_googl  \n",
       " Date                      \n",
       " 2014-08-01      44266000  \n",
       " 2014-08-04      30388000  \n",
       " 2014-08-05      32876000  \n",
       " 2014-08-06      26456000  \n",
       " 2014-08-07      23260000  \n",
       " ...                  ...  \n",
       " 2016-11-22      27884000  \n",
       " 2016-11-23      26260000  \n",
       " 2016-11-25      12270000  \n",
       " 2016-11-28      51508000  \n",
       " 2016-11-29      31240000  \n",
       " \n",
       " [588 rows x 6 columns]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e4474-1678-4027-8f03-ce174fba0ce1",
   "metadata": {},
   "source": [
    "## Stationarity Check - ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e1fe25-c36a-4ea7-a13f-c8418d704d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns for IBM:\n",
      "['adj close_ibm', 'close_ibm', 'high_ibm', 'low_ibm', 'open_ibm', 'volume_ibm']\n",
      "\n",
      "Selected close column for IBM: adj close_ibm\n",
      "\n",
      "Stationarity Test Results for IBM - Original Series:\n",
      "ADF Statistic: -2.088860581211881\n",
      "p-value: 0.2490173448800515\n",
      "Critical Values:\n",
      "\t1%: -3.4415393130846725\n",
      "\t5%: -2.866476335860869\n",
      "\t10%: -2.5693989358590006\n",
      "\n",
      "Is the series stationary? False\n",
      "\n",
      "Stationarity Test Results for IBM - Differenced Series:\n",
      "ADF Statistic: -18.298353095522632\n",
      "p-value: 2.2894276967682354e-30\n",
      "Critical Values:\n",
      "\t1%: -3.4415777369651717\n",
      "\t5%: -2.866493255736561\n",
      "\t10%: -2.569407951640003\n",
      "\n",
      "Is the series stationary? True\n",
      "\n",
      "Differenced data saved to datasets/IBM_stock_differenced.csv\n",
      "\n",
      "Columns for AAPL:\n",
      "['adj close_aapl', 'close_aapl', 'high_aapl', 'low_aapl', 'open_aapl', 'volume_aapl']\n",
      "\n",
      "Selected close column for AAPL: adj close_aapl\n",
      "\n",
      "Stationarity Test Results for AAPL - Original Series:\n",
      "ADF Statistic: -2.300186592510218\n",
      "p-value: 0.17190779877982987\n",
      "Critical Values:\n",
      "\t1%: -3.4415393130846725\n",
      "\t5%: -2.866476335860869\n",
      "\t10%: -2.5693989358590006\n",
      "\n",
      "Is the series stationary? False\n",
      "\n",
      "Stationarity Test Results for AAPL - Differenced Series:\n",
      "ADF Statistic: -23.726885277260244\n",
      "p-value: 0.0\n",
      "Critical Values:\n",
      "\t1%: -3.4415584920942424\n",
      "\t5%: -2.866484781324317\n",
      "\t10%: -2.569403436033035\n",
      "\n",
      "Is the series stationary? True\n",
      "\n",
      "Differenced data saved to datasets/AAPL_stock_differenced.csv\n",
      "\n",
      "Columns for META:\n",
      "['adj close_meta', 'close_meta', 'high_meta', 'low_meta', 'open_meta', 'volume_meta']\n",
      "\n",
      "Selected close column for META: adj close_meta\n",
      "\n",
      "Stationarity Test Results for META - Original Series:\n",
      "ADF Statistic: -0.9044694941019292\n",
      "p-value: 0.7864969858297622\n",
      "Critical Values:\n",
      "\t1%: -3.4416553818946145\n",
      "\t5%: -2.8665274458710064\n",
      "\t10%: -2.5694261699959413\n",
      "\n",
      "Is the series stationary? False\n",
      "\n",
      "Stationarity Test Results for META - Differenced Series:\n",
      "ADF Statistic: -11.865305440212426\n",
      "p-value: 6.697320344049954e-22\n",
      "Critical Values:\n",
      "\t1%: -3.4416553818946145\n",
      "\t5%: -2.8665274458710064\n",
      "\t10%: -2.5694261699959413\n",
      "\n",
      "Is the series stationary? True\n",
      "\n",
      "Differenced data saved to datasets/META_stock_differenced.csv\n",
      "\n",
      "Columns for GOOGL:\n",
      "['adj close_googl', 'close_googl', 'high_googl', 'low_googl', 'open_googl', 'volume_googl']\n",
      "\n",
      "Selected close column for GOOGL: adj close_googl\n",
      "\n",
      "Stationarity Test Results for GOOGL - Original Series:\n",
      "ADF Statistic: -1.0247091062627205\n",
      "p-value: 0.744145891373285\n",
      "Critical Values:\n",
      "\t1%: -3.4415970480373046\n",
      "\t5%: -2.866501759246704\n",
      "\t10%: -2.5694124827594296\n",
      "\n",
      "Is the series stationary? False\n",
      "\n",
      "Stationarity Test Results for GOOGL - Differenced Series:\n",
      "ADF Statistic: -14.769602684392176\n",
      "p-value: 2.3335687650442352e-27\n",
      "Critical Values:\n",
      "\t1%: -3.4415970480373046\n",
      "\t5%: -2.866501759246704\n",
      "\t10%: -2.5694124827594296\n",
      "\n",
      "Is the series stationary? True\n",
      "\n",
      "Differenced data saved to datasets/GOOGL_stock_differenced.csv\n",
      "\n",
      "Stationarity check and differencing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the tickers\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "input_folder = \"datasets\"\n",
    "output_folder = \"datasets\"\n",
    "\n",
    "# Function to perform stationarity test\n",
    "def check_stationarity(series, ticker, column):\n",
    "    # Perform Augmented Dickey-Fuller test\n",
    "    result = adfuller(series.dropna())\n",
    "    \n",
    "    print(f'\\nStationarity Test Results for {ticker} - {column}:')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "    \n",
    "    # Determine stationarity\n",
    "    alpha = 0.05\n",
    "    is_stationary = result[1] <= alpha\n",
    "    print(f'\\nIs the series stationary? {is_stationary}')\n",
    "    \n",
    "    return is_stationary\n",
    "\n",
    "# Function to difference the series\n",
    "def difference_series(series):\n",
    "    # First-order differencing\n",
    "    return series.diff().dropna()\n",
    "\n",
    "# Function to process each stock\n",
    "def process_stock_stationarity(ticker):\n",
    "    # Read the cleaned CSV file\n",
    "    input_path = os.path.join(input_folder, f'{ticker}_stock_cleaned.csv')\n",
    "    df = pd.read_csv(input_path, parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    # Print column names for debugging\n",
    "    print(f\"\\nColumns for {ticker}:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Select the 'close' column (now with more robust selection)\n",
    "    close_col = [col for col in df.columns if 'close' in col.lower()][0]\n",
    "    print(f\"\\nSelected close column for {ticker}: {close_col}\")\n",
    "    \n",
    "    series = df[close_col]\n",
    "    \n",
    "    # Check original series stationarity\n",
    "    original_stationary = check_stationarity(series, ticker, 'Original Series')\n",
    "    \n",
    "    # If not stationary, apply differencing\n",
    "    if not original_stationary:\n",
    "        # Perform first-order differencing\n",
    "        differenced_series = difference_series(series)\n",
    "        \n",
    "        # Check stationarity of differenced series\n",
    "        differenced_stationary = check_stationarity(differenced_series, ticker, 'Differenced Series')\n",
    "        \n",
    "        # Plot original and differenced series\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.subplot(2,1,1)\n",
    "        series.plot(title=f'{ticker} - Original Close Price')\n",
    "        plt.subplot(2,1,2)\n",
    "        differenced_series.plot(title=f'{ticker} - Differenced Close Price')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder, f'{ticker}_stationarity_plot.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Create a new dataframe with differenced data\n",
    "        df_differenced = df.copy()\n",
    "        df_differenced[close_col] = np.nan\n",
    "        df_differenced.loc[differenced_series.index, close_col] = differenced_series\n",
    "        \n",
    "        # Save differenced data\n",
    "        output_path = os.path.join(output_folder, f'{ticker}_stock_differenced.csv')\n",
    "        df_differenced.to_csv(output_path, index=True)\n",
    "        print(f'\\nDifferenced data saved to {output_path}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process each stock\n",
    "processed_datasets = {}\n",
    "for ticker in tickers:\n",
    "    processed_datasets[ticker] = process_stock_stationarity(ticker)\n",
    "\n",
    "print(\"\\nStationarity check and differencing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e4f8e-8283-4794-8773-c3bf3162f3cb",
   "metadata": {},
   "source": [
    "# ARIMA model for short term dependecies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea055b-94e6-4c4d-a2cb-455d4314322b",
   "metadata": {},
   "source": [
    "## ARIMA Model setup\n",
    "- ACF and PACF to identify values for the AR and MA\n",
    "- Buildign and training the ARIMA model on the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f56c2cd-e86b-49bd-a1d2-baddb2fe3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Split:\n",
      "Total samples: 588\n",
      "Training samples: 470\n",
      "Testing samples: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IBM - Best ARIMA Parameters: (1, 1, 2)\n",
      "Best AIC Score: 1593.0086475685769\n",
      "\n",
      "IBM Model Performance:\n",
      "Mean Squared Error (MSE): 1.1919617785841523\n",
      "Root Mean Squared Error (RMSE): 1.0917700209220587\n",
      "Mean Absolute Error (MAE): 0.7766912353489308\n",
      "R-squared (R2) Score: -0.005197560125741463\n",
      "\n",
      "Dataset Split:\n",
      "Total samples: 588\n",
      "Training samples: 470\n",
      "Testing samples: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAPL - Best ARIMA Parameters: (0, 1, 1)\n",
      "Best AIC Score: 503.5547381106669\n",
      "\n",
      "AAPL Model Performance:\n",
      "Mean Squared Error (MSE): 0.09686749767606534\n",
      "Root Mean Squared Error (RMSE): 0.31123543769318\n",
      "Mean Absolute Error (MAE): 0.21505553317934456\n",
      "R-squared (R2) Score: -0.013794053591491773\n",
      "\n",
      "Dataset Split:\n",
      "Total samples: 588\n",
      "Training samples: 470\n",
      "Testing samples: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "META - Best ARIMA Parameters: (0, 1, 1)\n",
      "Best AIC Score: 1831.6827630101925\n",
      "\n",
      "META Model Performance:\n",
      "Mean Squared Error (MSE): 2.274195577279143\n",
      "Root Mean Squared Error (RMSE): 1.5080436257877763\n",
      "Mean Absolute Error (MAE): 1.07540544412904\n",
      "R-squared (R2) Score: -0.0003945206048310279\n",
      "\n",
      "Dataset Split:\n",
      "Total samples: 588\n",
      "Training samples: 470\n",
      "Testing samples: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOOGL - Best ARIMA Parameters: (0, 1, 1)\n",
      "Best AIC Score: 733.9616871016435\n",
      "\n",
      "GOOGL Model Performance:\n",
      "Mean Squared Error (MSE): 0.17236297238608253\n",
      "Root Mean Squared Error (RMSE): 0.415166198511009\n",
      "Mean Absolute Error (MAE): 0.29804776378267145\n",
      "R-squared (R2) Score: -0.0003261940377481398\n",
      "\n",
      "ARIMA model analysis complete for all stocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enigma/Projects/CSM_finalproject/csmass_env/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "\n",
    "# Define the tickers\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "input_folder = \"datasets\"\n",
    "output_folder = \"datasets\"\n",
    "\n",
    "# Function to create train-test split\n",
    "def create_train_test_split(series, test_size=0.2):\n",
    "    # Calculate split index\n",
    "    split_index = int(len(series) * (1 - test_size))\n",
    "    \n",
    "    # Split the series\n",
    "    train = series[:split_index]\n",
    "    test = series[split_index:]\n",
    "    \n",
    "    print(\"\\nDataset Split:\")\n",
    "    print(f\"Total samples: {len(series)}\")\n",
    "    print(f\"Training samples: {len(train)}\")\n",
    "    print(f\"Testing samples: {len(test)}\")\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# Function to plot actual vs predicted\n",
    "def plot_actual_vs_predicted(test_index, actual, predicted, ticker):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(test_index, actual, label='Actual', color='blue')\n",
    "    plt.plot(test_index, predicted, label='Predicted', color='red', linestyle='--')\n",
    "    plt.title(f'{ticker} - Actual vs Predicted Close Prices')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f'{ticker}_arima_actual_vs_predicted.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Function to build and evaluate ARIMA model\n",
    "def build_arima_model(ticker):\n",
    "    # Read the cleaned CSV file\n",
    "    input_path = os.path.join(input_folder, f'{ticker}_stock_differenced.csv')\n",
    "    df = pd.read_csv(input_path, parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    # Select the close column\n",
    "    close_col = [col for col in df.columns if 'close' in col.lower()][0]\n",
    "    series = df[close_col]\n",
    "    \n",
    "    # Create train-test split\n",
    "    train, test = create_train_test_split(series)\n",
    "    \n",
    "    # Determine best ARIMA parameters using grid search\n",
    "    best_params = None\n",
    "    best_aic = float('inf')\n",
    "    \n",
    "    # Try different ARIMA parameter combinations\n",
    "    p_range = range(0, 3)\n",
    "    d = 1      # determined from previous step - adf test, we differenced only once to attain stationarity\n",
    "    q_range = range(0, 3)\n",
    "    \n",
    "    for p in p_range:\n",
    "          for q in q_range:\n",
    "              try:\n",
    "                  # Fit ARIMA model\n",
    "                  model = ARIMA(train, order=(p,d,q))\n",
    "                  model_fit = model.fit()\n",
    "                  \n",
    "                  # Compare AIC\n",
    "                  if model_fit.aic < best_aic:\n",
    "                      best_aic = model_fit.aic\n",
    "                      best_params = (p,d,q)\n",
    "              except Exception as e:\n",
    "                  continue\n",
    "    \n",
    "    print(f\"\\n{ticker} - Best ARIMA Parameters: {best_params}\")\n",
    "    print(f\"Best AIC Score: {best_aic}\")\n",
    "    \n",
    "    # Fit the best ARIMA model\n",
    "    final_model = ARIMA(train, order=best_params)\n",
    "    final_model_fit = final_model.fit()\n",
    "    \n",
    "    # Generate forecast for test set\n",
    "    forecast = final_model_fit.forecast(steps=len(test))\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    mse = mean_squared_error(test, forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test, forecast)\n",
    "    r2 = r2_score(test, forecast)\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plot_actual_vs_predicted(test.index, test, forecast, ticker)\n",
    "    \n",
    "    # Print model performance\n",
    "    print(f\"\\n{ticker} Model Performance:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R2) Score: {r2}\")\n",
    "    \n",
    "    # Save model summary\n",
    "    with open(os.path.join(output_folder, f'{ticker}_arima_model_summary.txt'), 'w') as f:\n",
    "        f.write(str(final_model_fit.summary()))\n",
    "    \n",
    "    return {\n",
    "        'model': final_model_fit,\n",
    "        'params': best_params,\n",
    "        'forecast': forecast,\n",
    "        'metrics': {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Process each stock\n",
    "arima_results = {}\n",
    "for ticker in tickers:\n",
    "    arima_results[ticker] = build_arima_model(ticker)\n",
    "\n",
    "print(\"\\nARIMA model analysis complete for all stocks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aefe01-077c-4208-9106-5eae132b16d6",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7643f9a-9142-415c-bad2-8736a1b0bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 22:30:21.438780: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 22:30:21.446436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733072421.456804   73832 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733072421.459601   73832 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 22:30:21.472037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for IBM: Index(['adj close_ibm', 'close_ibm', 'high_ibm', 'low_ibm', 'open_ibm',\n",
      "       'volume_ibm'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733072422.690941   73832 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9225 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733072424.438475   73955 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1511 - mae: 0.3221 - val_loss: 0.0085 - val_mae: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0176 - mae: 0.1089 - val_loss: 0.0019 - val_mae: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0127 - mae: 0.0917 - val_loss: 0.0058 - val_mae: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0793 - val_loss: 0.0019 - val_mae: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0837 - val_loss: 0.0049 - val_mae: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0077 - mae: 0.0720 - val_loss: 0.0018 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0705 - val_loss: 0.0021 - val_mae: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - mae: 0.0714 - val_loss: 0.0043 - val_mae: 0.0563 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0074 - mae: 0.0682 - val_loss: 0.0018 - val_mae: 0.0355 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mae: 0.0652 - val_loss: 0.0026 - val_mae: 0.0421 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - mae: 0.0658 - val_loss: 0.0040 - val_mae: 0.0534 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mae: 0.0665 - val_loss: 0.0024 - val_mae: 0.0403 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "# Define the tickers\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "input_folder = \"datasets\"\n",
    "output_folder = \"datasets\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Function to create train-test split\n",
    "def create_train_test_split(series, test_size=0.2):\n",
    "    split_index = int(len(series) * (1 - test_size))\n",
    "    train = series[:split_index]\n",
    "    test = series[split_index:]\n",
    "    return train, test\n",
    "\n",
    "# Function to add moving averages\n",
    "def add_technical_indicators(df, window_sizes=[5, 10, 20]):\n",
    "    for window in window_sizes:\n",
    "        df[f'MA_{window}'] = df['Close'].rolling(window=window).mean()\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values after rolling\n",
    "    return df\n",
    "\n",
    "# Function to prepare data for LSTM\n",
    "def prepare_data_for_lstm(df, window_size=60, feature_columns=['Close']):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df[feature_columns])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(scaled_data)):\n",
    "        X.append(scaled_data[i-window_size:i])\n",
    "        y.append(scaled_data[i, 0])  # Target column is the first column ('Close')\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y, scaler\n",
    "\n",
    "# LSTM Model Builder\n",
    "def build_optimized_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(units=1))  # Output layer\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Function to train and evaluate the LSTM\n",
    "def train_and_evaluate_lstm(ticker, window_size=60, epochs=100, batch_size=32, validation_split=0.1):\n",
    "    # Read the cleaned CSV file\n",
    "    input_path = os.path.join(input_folder, f'{ticker}_stock_cleaned.csv')\n",
    "    df = pd.read_csv(input_path, parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    # Check and print the column names to debug\n",
    "    print(f\"Columns for {ticker}: {df.columns}\")\n",
    "    \n",
    "    # Dynamically find the 'close' column (case insensitive search)\n",
    "    close_col = None\n",
    "    for col in df.columns:\n",
    "        if 'close' in col.lower():\n",
    "            close_col = col\n",
    "            break\n",
    "    if close_col is None:\n",
    "        raise KeyError(\"No 'close' or similar column found in the dataset.\")\n",
    "    \n",
    "    # Add technical indicators\n",
    "    df['Close'] = df[close_col]  # Use the identified 'close' column as 'Close'\n",
    "    df = add_technical_indicators(df)\n",
    "    \n",
    "    # Create train-test split\n",
    "    train, test = create_train_test_split(df)\n",
    "    \n",
    "    # Prepare data for LSTM\n",
    "    X_train, y_train, scaler = prepare_data_for_lstm(train, window_size, feature_columns=['Close'] + [col for col in df.columns if 'MA' in col])\n",
    "    X_test, y_test, _ = prepare_data_for_lstm(test, window_size, feature_columns=['Close'] + [col for col in df.columns if 'MA' in col])\n",
    "    \n",
    "    # Build the model\n",
    "    model = build_optimized_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(np.hstack([predictions, np.zeros((predictions.shape[0], X_test.shape[2]-1))]))[:, 0]\n",
    "    y_test_actual = scaler.inverse_transform(np.hstack([y_test.reshape(-1, 1), np.zeros((y_test.shape[0], X_test.shape[2]-1))]))[:, 0]\n",
    "    \n",
    "    # Error Metrics\n",
    "    mse = mean_squared_error(y_test_actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_actual, predictions)\n",
    "    r2 = r2_score(y_test_actual, predictions)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test.index[window_size:], y_test_actual, label='Actual', color='blue')\n",
    "    plt.plot(test.index[window_size:], predictions, label='Predicted', color='red', linestyle='--')\n",
    "    plt.title(f'{ticker} - Actual vs Predicted')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f'{ticker}_lstm_results.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{ticker} - MSE: {mse}, RMSE: {rmse}, MAE: {mae}, R2: {r2}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'metrics': {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2},\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "# Process each stock\n",
    "results = {}\n",
    "for ticker in tickers:\n",
    "    results[ticker] = train_and_evaluate_lstm(ticker)\n",
    "\n",
    "print(\"LSTM analysis complete for all stocks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1e028-bfba-41cc-81b0-7b936bc5a8e8",
   "metadata": {},
   "source": [
    "# Combined Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39acb6-bb36-461b-a278-53a2f748125a",
   "metadata": {},
   "source": [
    "##  ARIMA Residuals Fed into LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9024d-84f3-4339-83ac-fec29ad7cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "# Define the tickers\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "input_folder = \"datasets\"\n",
    "output_folder = \"datasets\"\n",
    "\n",
    "# Function to create train-test split\n",
    "def create_train_test_split(series, test_size=0.2):\n",
    "    # Calculate split index\n",
    "    split_index = int(len(series) * (1 - test_size))\n",
    "    \n",
    "    # Split the series\n",
    "    train = series[:split_index]\n",
    "    test = series[split_index:]\n",
    "    \n",
    "    print(\"\\nDataset Split:\")\n",
    "    print(f\"Total samples: {len(series)}\")\n",
    "    print(f\"Training samples: {len(train)}\")\n",
    "    print(f\"Testing samples: {len(test)}\")\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# Function to plot actual vs predicted\n",
    "def plot_actual_vs_predicted(test_index, actual, predicted, ticker):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(test_index, actual, label='Actual', color='blue')\n",
    "    plt.plot(test_index, predicted, label='Predicted', color='red', linestyle='--')\n",
    "    plt.title(f'{ticker} - Actual vs Predicted Close Prices')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f'{ticker}_hybrid_actual_vs_predicted.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Function to prepare data for LSTM\n",
    "def prepare_data_for_lstm(series, window_size=60):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(series.reshape(-1, 1))\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(scaled_data)):\n",
    "        X.append(scaled_data[i-window_size:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    return X, y, scaler\n",
    "\n",
    "# Function to build and evaluate hybrid ARIMA-LSTM model\n",
    "def build_hybrid_model(ticker, window_size=60, epochs=50, batch_size=32):\n",
    "    # Read the cleaned CSV file\n",
    "    input_path = os.path.join(input_folder, f'{ticker}_stock_cleaned.csv')\n",
    "    df = pd.read_csv(input_path, parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    # Select the close column\n",
    "    close_col = [col for col in df.columns if 'close' in col.lower()][0]\n",
    "    series = df[close_col]\n",
    "    \n",
    "    # Create train-test split\n",
    "    train, test = create_train_test_split(series)\n",
    "    \n",
    "    # Fit ARIMA model\n",
    "    arima_model = ARIMA(train, order=(1, 1, 1))\n",
    "    arima_fit = arima_model.fit()\n",
    "    \n",
    "    # Generate ARIMA predictions\n",
    "    arima_predictions = arima_fit.forecast(steps=len(test))\n",
    "    \n",
    "    # Check for NaN values in ARIMA predictions and handle them\n",
    "    if np.isnan(arima_predictions).any():\n",
    "        arima_predictions = np.nan_to_num(arima_predictions, nan=0.0)\n",
    "    \n",
    "    # Calculate ARIMA residuals\n",
    "    arima_residuals = test - arima_predictions\n",
    "    \n",
    "    # Check for NaN values in ARIMA residuals and handle them\n",
    "    if np.isnan(arima_residuals).any():\n",
    "        arima_residuals = np.nan_to_num(arima_residuals, nan=0.0)\n",
    "    \n",
    "    # Prepare data for LSTM using ARIMA residuals\n",
    "    X_train, y_train, scaler = prepare_data_for_lstm(arima_residuals, window_size)\n",
    "    X_test, y_test, _ = prepare_data_for_lstm(arima_residuals, window_size)\n",
    "    \n",
    "    # Check for NaN values in training data\n",
    "    if np.isnan(X_train).any() or np.isnan(y_train).any():\n",
    "        raise ValueError(\"Training data contains NaN values.\")\n",
    "    \n",
    "    # Build LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1), kernel_initializer=GlorotUniform()))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False, kernel_initializer=GlorotUniform()))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=25, kernel_initializer=GlorotUniform()))\n",
    "    model.add(Dense(units=1, kernel_initializer=GlorotUniform()))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    \n",
    "    # Generate predictions\n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "    \n",
    "    # Check for NaN values in LSTM predictions and handle them\n",
    "    if np.isnan(lstm_predictions).any():\n",
    "        lstm_predictions = np.nan_to_num(lstm_predictions, nan=0.0)\n",
    "    \n",
    "    # Ensure LSTM predictions match the length of ARIMA predictions\n",
    "    if len(lstm_predictions) > len(arima_predictions):\n",
    "        lstm_predictions = lstm_predictions[:len(arima_predictions)]\n",
    "    elif len(lstm_predictions) < len(arima_predictions):\n",
    "        lstm_predictions = np.pad(lstm_predictions, (0, len(arima_predictions) - len(lstm_predictions)), 'edge')\n",
    "    \n",
    "    # Combine ARIMA and LSTM predictions\n",
    "    combined_predictions = arima_predictions + lstm_predictions.flatten()\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    mse = mean_squared_error(test, combined_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test, combined_predictions)\n",
    "    r2 = r2_score(test, combined_predictions)\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plot_actual_vs_predicted(test.index, test, combined_predictions, ticker)\n",
    "    \n",
    "    # Print model performance\n",
    "    print(f\"\\n{ticker} Model Performance:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R2) Score: {r2}\")\n",
    "    \n",
    "    # Save model summary\n",
    "    with open(os.path.join(output_folder, f'{ticker}_model_summary.txt'), 'w') as f:\n",
    "        f.write(str(model.summary()))\n",
    "    \n",
    "    return {\n",
    "        'arima_model': arima_fit,\n",
    "        'lstm_model': model,\n",
    "        'predictions': combined_predictions,\n",
    "        'metrics': {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Process each stock\n",
    "hybrid_results = {}\n",
    "for ticker in tickers:\n",
    "    hybrid_results[ticker] = build_hybrid_model(ticker)\n",
    "\n",
    "print(\"\\nHybrid ARIMA-LSTM model analysis complete for all stocks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2634d-feab-43a6-9302-db4b154e1753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
