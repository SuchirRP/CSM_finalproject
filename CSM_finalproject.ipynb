{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae294d7a-39fa-4e39-bd21-8b9e392b2dd0",
   "metadata": {},
   "source": [
    "# Data Collection and PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25d37a-5899-47f9-8741-53b9aa2606bf",
   "metadata": {},
   "source": [
    "## Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51f4c0a-6898-47d6-a89c-1e13dab2e002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data for IBM:\n",
      "            adj close_ibm   close_ibm    high_ibm     low_ibm    open_ibm  \\\n",
      "Date                                                                        \n",
      "2014-08-01     115.999741  180.831741  183.078400  180.554489  182.122375   \n",
      "2014-08-04     116.300240  181.300186  181.596558  180.305923  181.022949   \n",
      "2014-08-05     114.742538  178.871887  180.879547  178.240921  180.449326   \n",
      "2014-08-06     114.724007  177.791580  178.661575  176.328873  177.208420   \n",
      "2014-08-07     113.693794  176.195023  178.470367  175.506699  178.432129   \n",
      "\n",
      "            volume_ibm  \n",
      "Date                    \n",
      "2014-08-01     5419431  \n",
      "2014-08-04     2223691  \n",
      "2014-08-05     3460063  \n",
      "2014-08-06     4023962  \n",
      "2014-08-07     2833196  \n",
      "Saved IBM data to datasets/IBM_stock.csv\n",
      "\n",
      "Data for AAPL:\n",
      "            adj close_aapl  close_aapl  high_aapl   low_aapl  open_aapl  \\\n",
      "Date                                                                      \n",
      "2014-08-01       21.209681   24.032499  24.155001  23.702499  23.725000   \n",
      "2014-08-04       21.090534   23.897499  24.145000  23.792500  24.092501   \n",
      "2014-08-05       20.986845   23.780001  23.920000  23.590000  23.840000   \n",
      "2014-08-06       20.951542   23.740000  23.870001  23.677500  23.687500   \n",
      "2014-08-07       20.949318   23.620001  23.987499  23.525000  23.732500   \n",
      "\n",
      "            volume_aapl  \n",
      "Date                     \n",
      "2014-08-01    194044000  \n",
      "2014-08-04    159832000  \n",
      "2014-08-05    223732000  \n",
      "2014-08-06    154232000  \n",
      "2014-08-07    186844000  \n",
      "Saved AAPL data to datasets/AAPL_stock.csv\n",
      "\n",
      "Data for META:\n",
      "            adj close_meta  close_meta  high_meta   low_meta  open_meta  \\\n",
      "Date                                                                      \n",
      "2014-08-01       72.142792   72.360001  73.220001  71.550003  72.220001   \n",
      "2014-08-04       73.289337   73.510002  73.879997  72.360001  72.360001   \n",
      "2014-08-05       72.471794   72.690002  73.589996  72.180000  73.199997   \n",
      "2014-08-06       72.252457   72.470001  73.720001  71.790001  72.019997   \n",
      "2014-08-07       72.950356   73.169998  74.000000  72.699997  73.000000   \n",
      "\n",
      "            volume_meta  \n",
      "Date                     \n",
      "2014-08-01     43535000  \n",
      "2014-08-04     30777000  \n",
      "2014-08-05     34986000  \n",
      "2014-08-06     30986000  \n",
      "2014-08-07     38141000  \n",
      "Saved META data to datasets/META_stock.csv\n",
      "\n",
      "Data for GOOGL:\n",
      "            adj close_googl  close_googl  high_googl  low_googl  open_googl  \\\n",
      "Date                                                                          \n",
      "2014-08-01        28.609159    28.680000   29.171499  28.514999     28.9275   \n",
      "2014-08-04        29.041588    29.113501   29.191000  28.613001     28.8255   \n",
      "2014-08-05        28.586216    28.657000   29.010000  28.515499     28.9690   \n",
      "2014-08-06        28.653551    28.724501   28.931999  28.372499     28.4750   \n",
      "2014-08-07        28.519880    28.590500   28.915501  28.471500     28.8025   \n",
      "\n",
      "            volume_googl  \n",
      "Date                      \n",
      "2014-08-01      44266000  \n",
      "2014-08-04      30388000  \n",
      "2014-08-05      32876000  \n",
      "2014-08-06      26456000  \n",
      "2014-08-07      23260000  \n",
      "Saved GOOGL data to datasets/GOOGL_stock.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd  # Ensure pandas is imported for MultiIndex handling\n",
    "\n",
    "# Define stock tickers and date range\n",
    "start_date = \"2014-08-01\"\n",
    "end_date = \"2016-11-30\"\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "\n",
    "# Create a folder named 'datasets' if it doesn't exist\n",
    "output_folder = \"datasets\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Download data for each stock and save with standardized column names\n",
    "for ticker in tickers:\n",
    "    # Download the stock data\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Check if columns are a MultiIndex and flatten if necessary\n",
    "    if isinstance(stock_data.columns, pd.MultiIndex):\n",
    "        stock_data.columns = ['_'.join(col).strip().lower() for col in stock_data.columns]\n",
    "    else:\n",
    "        stock_data.columns = [col.replace(' ', '_').lower() for col in stock_data.columns]\n",
    "    \n",
    "    # Print the first few rows of the data\n",
    "    print(f\"\\nData for {ticker}:\")\n",
    "    print(stock_data.head())\n",
    "    \n",
    "    # Save to CSV in the 'datasets' folder\n",
    "    file_path = os.path.join(output_folder, f'{ticker}_stock.csv')\n",
    "    stock_data.to_csv(file_path, index=True)\n",
    "\n",
    "    print(f\"Saved {ticker} data to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ef8e7-5588-403f-a905-2eb44b7ab2a5",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6383c67-1616-4e24-97c6-897110a4fbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning data for IBM...\n",
      "Cleaned data for IBM:\n",
      "            adj close_ibm   close_ibm    high_ibm     low_ibm    open_ibm  \\\n",
      "Date                                                                        \n",
      "2014-08-01     115.999741  180.831741  183.078400  180.554489  182.122375   \n",
      "2014-08-04     116.300240  181.300186  181.596558  180.305923  181.022949   \n",
      "2014-08-05     114.742538  178.871887  180.879547  178.240921  180.449326   \n",
      "2014-08-06     114.724007  177.791580  178.661575  176.328873  177.208420   \n",
      "2014-08-07     113.693794  176.195023  178.470367  175.506699  178.432129   \n",
      "\n",
      "            volume_ibm  \n",
      "Date                    \n",
      "2014-08-01     5419431  \n",
      "2014-08-04     2223691  \n",
      "2014-08-05     3460063  \n",
      "2014-08-06     4023962  \n",
      "2014-08-07     2833196  \n",
      "Saved cleaned data for IBM to datasets/IBM_stock_cleaned.csv\n",
      "\n",
      "Cleaning data for AAPL...\n",
      "Cleaned data for AAPL:\n",
      "            adj close_aapl  close_aapl  high_aapl   low_aapl  open_aapl  \\\n",
      "Date                                                                      \n",
      "2014-08-01       21.209681   24.032499  24.155001  23.702499  23.725000   \n",
      "2014-08-04       21.090534   23.897499  24.145000  23.792500  24.092501   \n",
      "2014-08-05       20.986845   23.780001  23.920000  23.590000  23.840000   \n",
      "2014-08-06       20.951542   23.740000  23.870001  23.677500  23.687500   \n",
      "2014-08-07       20.949318   23.620001  23.987499  23.525000  23.732500   \n",
      "\n",
      "            volume_aapl  \n",
      "Date                     \n",
      "2014-08-01    194044000  \n",
      "2014-08-04    159832000  \n",
      "2014-08-05    223732000  \n",
      "2014-08-06    154232000  \n",
      "2014-08-07    186844000  \n",
      "Saved cleaned data for AAPL to datasets/AAPL_stock_cleaned.csv\n",
      "\n",
      "Cleaning data for META...\n",
      "Cleaned data for META:\n",
      "            adj close_meta  close_meta  high_meta   low_meta  open_meta  \\\n",
      "Date                                                                      \n",
      "2014-08-01       72.142792   72.360001  73.220001  71.550003  72.220001   \n",
      "2014-08-04       73.289337   73.510002  73.879997  72.360001  72.360001   \n",
      "2014-08-05       72.471794   72.690002  73.589996  72.180000  73.199997   \n",
      "2014-08-06       72.252457   72.470001  73.720001  71.790001  72.019997   \n",
      "2014-08-07       72.950356   73.169998  74.000000  72.699997  73.000000   \n",
      "\n",
      "            volume_meta  \n",
      "Date                     \n",
      "2014-08-01     43535000  \n",
      "2014-08-04     30777000  \n",
      "2014-08-05     34986000  \n",
      "2014-08-06     30986000  \n",
      "2014-08-07     38141000  \n",
      "Saved cleaned data for META to datasets/META_stock_cleaned.csv\n",
      "\n",
      "Cleaning data for GOOGL...\n",
      "Cleaned data for GOOGL:\n",
      "            adj close_googl  close_googl  high_googl  low_googl  open_googl  \\\n",
      "Date                                                                          \n",
      "2014-08-01        28.609159    28.680000   29.171499  28.514999     28.9275   \n",
      "2014-08-04        29.041588    29.113501   29.191000  28.613001     28.8255   \n",
      "2014-08-05        28.586216    28.657000   29.010000  28.515499     28.9690   \n",
      "2014-08-06        28.653551    28.724501   28.931999  28.372499     28.4750   \n",
      "2014-08-07        28.519880    28.590500   28.915501  28.471500     28.8025   \n",
      "\n",
      "            volume_googl  \n",
      "Date                      \n",
      "2014-08-01      44266000  \n",
      "2014-08-04      30388000  \n",
      "2014-08-05      32876000  \n",
      "2014-08-06      26456000  \n",
      "2014-08-07      23260000  \n",
      "Saved cleaned data for GOOGL to datasets/GOOGL_stock_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean the stock data by:\n",
    "    1. Handling missing values.\n",
    "    2. Detecting and treating outliers using the IQR method.\n",
    "    3. Applying log transformation to ensure stationarity for close prices.\n",
    "    \"\"\"\n",
    "    # Handle missing values by forward-fill, backward-fill, or dropping\n",
    "    if df.isnull().values.any():\n",
    "        print(\"Missing values found. Filling missing values...\")\n",
    "        df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "        df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "    \n",
    "    # Detect and handle outliers (e.g., using the IQR method)\n",
    "    for column in ['open', 'high', 'low', 'close', 'adj_close']:\n",
    "        if column in df.columns:\n",
    "            Q1 = df[column].quantile(0.25)\n",
    "            Q3 = df[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Replace outliers with the nearest bound\n",
    "            df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "            df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "    \n",
    "    # Apply log transformation to the 'close' prices for stationarity\n",
    "    if 'close' in df.columns:\n",
    "        df['log_close'] = np.log(df['close'] + 1)  # Add 1 to avoid log(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load, clean and save the cleaned data\n",
    "output_folder = \"datasets\"\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Load the raw data\n",
    "    file_path = os.path.join(output_folder, f'{ticker}_stock.csv')\n",
    "    stock_data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # Clean the data\n",
    "    print(f\"\\nCleaning data for {ticker}...\")\n",
    "    cleaned_data = clean_data(stock_data)\n",
    "    \n",
    "    # Print the first few rows of the cleaned data\n",
    "    print(f\"Cleaned data for {ticker}:\")\n",
    "    print(cleaned_data.head())\n",
    "    \n",
    "    # Save the cleaned data to CSV\n",
    "    cleaned_file_path = os.path.join(output_folder, f'{ticker}_stock_cleaned.csv')\n",
    "    cleaned_data.to_csv(cleaned_file_path, index=True)\n",
    "    print(f\"Saved cleaned data for {ticker} to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01817758-0550-470a-b238-8e7b751cbaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'log_close_ibm' column for IBM.\n",
      "Saved updated data for IBM with 'log_close' column to datasets/IBM_stock_with_log.csv\n",
      "Created 'log_close_aapl' column for AAPL.\n",
      "Saved updated data for AAPL with 'log_close' column to datasets/AAPL_stock_with_log.csv\n",
      "Created 'log_close_meta' column for META.\n",
      "Saved updated data for META with 'log_close' column to datasets/META_stock_with_log.csv\n",
      "Created 'log_close_googl' column for GOOGL.\n",
      "Saved updated data for GOOGL with 'log_close' column to datasets/GOOGL_stock_with_log.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder where the cleaned data is stored\n",
    "output_folder = \"datasets\"\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "\n",
    "# Create the log_close_ column for each ticker\n",
    "for ticker in tickers:\n",
    "    # Load the cleaned data for each ticker\n",
    "    file_path = os.path.join(output_folder, f'{ticker}_stock_cleaned.csv')\n",
    "    stock_data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # Check if 'close' column exists before creating 'log_close'\n",
    "    close_col = f'close_{ticker.lower()}'\n",
    "    log_close_col = f'log_close_{ticker.lower()}'\n",
    "    \n",
    "    if close_col in stock_data.columns:\n",
    "        # Create the 'log_close' column by taking the log of 'close'\n",
    "        stock_data[log_close_col] = np.log(stock_data[close_col])\n",
    "        print(f\"Created '{log_close_col}' column for {ticker}.\")\n",
    "        \n",
    "        # Save the updated data with the new 'log_close' column\n",
    "        updated_file_path = os.path.join(output_folder, f'{ticker}_stock_with_log.csv')\n",
    "        stock_data.to_csv(updated_file_path, index=True)\n",
    "        print(f\"Saved updated data for {ticker} with 'log_close' column to {updated_file_path}\")\n",
    "    else:\n",
    "        print(f\"'{close_col}' column not found for {ticker}. Please check column names.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20245576-fd57-4e9b-b1dd-b8ffbbe95ea7",
   "metadata": {},
   "source": [
    "## Stationarity Check - Augmented Dickey-Fuller (ADF) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad73a7d-1619-4fdf-8b01-50aafd19d472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing stationarity check for IBM - close_ibm...\n",
      "ADF test for 'close_ibm' - ADF Statistic: -2.266411002310209, p-value: 0.18302997624844458\n",
      "The 'close_ibm' series is nonstationary. Applying differencing.\n",
      "\n",
      "Performing stationarity check for IBM - log_close_ibm...\n",
      "ADF test for 'log_close_ibm' - ADF Statistic: -2.1926190510998502, p-value: 0.20893521381882862\n",
      "The 'log_close_ibm' series is nonstationary. Applying differencing.\n",
      "Saved stationary data for IBM to datasets/IBM_stock_stationary.csv\n",
      "\n",
      "Performing stationarity check for AAPL - close_aapl...\n",
      "ADF test for 'close_aapl' - ADF Statistic: -2.1682503299850526, p-value: 0.2179698405819862\n",
      "The 'close_aapl' series is nonstationary. Applying differencing.\n",
      "\n",
      "Performing stationarity check for AAPL - log_close_aapl...\n",
      "ADF test for 'log_close_aapl' - ADF Statistic: -2.205287322269062, p-value: 0.2043320637396588\n",
      "The 'log_close_aapl' series is nonstationary. Applying differencing.\n",
      "Saved stationary data for AAPL to datasets/AAPL_stock_stationary.csv\n",
      "\n",
      "Performing stationarity check for META - close_meta...\n",
      "ADF test for 'close_meta' - ADF Statistic: -0.9044699259489827, p-value: 0.7864968429277457\n",
      "The 'close_meta' series is nonstationary. Applying differencing.\n",
      "\n",
      "Performing stationarity check for META - log_close_meta...\n",
      "ADF test for 'log_close_meta' - ADF Statistic: -1.0107730445946201, p-value: 0.7493148289145317\n",
      "The 'log_close_meta' series is nonstationary. Applying differencing.\n",
      "Saved stationary data for META to datasets/META_stock_stationary.csv\n",
      "\n",
      "Performing stationarity check for GOOGL - close_googl...\n",
      "ADF test for 'close_googl' - ADF Statistic: -1.0247096238028344, p-value: 0.7441456981659877\n",
      "The 'close_googl' series is nonstationary. Applying differencing.\n",
      "\n",
      "Performing stationarity check for GOOGL - log_close_googl...\n",
      "ADF test for 'log_close_googl' - ADF Statistic: -1.105682589673364, p-value: 0.7128004418085045\n",
      "The 'log_close_googl' series is nonstationary. Applying differencing.\n",
      "Saved stationary data for GOOGL to datasets/GOOGL_stock_stationary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import os\n",
    "\n",
    "# Define function to perform ADF test\n",
    "def adf_test(series):\n",
    "    result = adfuller(series.dropna())\n",
    "    return result[0], result[1]\n",
    "\n",
    "# Define folder where the updated data is stored\n",
    "output_folder = \"datasets\"\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "\n",
    "# Function to check stationarity for both 'close' and 'log_close'\n",
    "def check_stationarity():\n",
    "    for ticker in tickers:\n",
    "        # Load the updated data with the 'log_close' column\n",
    "        file_path = os.path.join(output_folder, f'{ticker}_stock_with_log.csv')\n",
    "        stock_data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        \n",
    "        # Define column names\n",
    "        close_col = f'close_{ticker.lower()}'\n",
    "        log_close_col = f'log_close_{ticker.lower()}'\n",
    "        \n",
    "        # Perform ADF test on the 'close' column\n",
    "        if close_col in stock_data.columns:\n",
    "            print(f\"\\nPerforming stationarity check for {ticker} - {close_col}...\")\n",
    "            adf_stat, p_value = adf_test(stock_data[close_col])\n",
    "            print(f\"ADF test for '{close_col}' - ADF Statistic: {adf_stat}, p-value: {p_value}\")\n",
    "            \n",
    "            if p_value > 0.05:\n",
    "                print(f\"The '{close_col}' series is nonstationary. Applying differencing.\")\n",
    "                stock_data[close_col] = stock_data[close_col].diff().dropna()  # First differencing\n",
    "            else:\n",
    "                print(f\"The '{close_col}' series is stationary.\")\n",
    "\n",
    "        # Perform ADF test on the 'log_close' column\n",
    "        if log_close_col in stock_data.columns:\n",
    "            print(f\"\\nPerforming stationarity check for {ticker} - {log_close_col}...\")\n",
    "            adf_stat, p_value = adf_test(stock_data[log_close_col])\n",
    "            print(f\"ADF test for '{log_close_col}' - ADF Statistic: {adf_stat}, p-value: {p_value}\")\n",
    "            \n",
    "            if p_value > 0.05:\n",
    "                print(f\"The '{log_close_col}' series is nonstationary. Applying differencing.\")\n",
    "                stock_data[log_close_col] = stock_data[log_close_col].diff().dropna()  # First differencing\n",
    "            else:\n",
    "                print(f\"The '{log_close_col}' series is stationary.\")\n",
    "        \n",
    "        # Save the stationary data to a new file\n",
    "        updated_file_path = os.path.join(output_folder, f'{ticker}_stock_stationary.csv')\n",
    "        stock_data.to_csv(updated_file_path, index=True)\n",
    "        print(f\"Saved stationary data for {ticker} to {updated_file_path}\")\n",
    "\n",
    "# Call the function to check stationarity for all tickers\n",
    "check_stationarity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495d5cb-b692-4955-b554-2a797f156e30",
   "metadata": {},
   "source": [
    "# Building ARIMA model fro short-term dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdca5c9-d531-4624-9ead-6cdffe7dacd2",
   "metadata": {},
   "source": [
    "## Arima Model Setup\n",
    "- Use the ACF (Auto-Correlation Function) and PACF (Partial Auto-Correlation Function) plots to identify potential values for the AR (Auto-Regressive) and MA (Moving Average) parameters.\n",
    "- Build and train the ARIMA model on the preprocessed series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43534c37-da34-46a4-9bc7-a63029bdde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting ACF and PACF for IBM...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Axes.stem() got an unexpected keyword argument 'use_line_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Plot ACF and PACF to identify parameters\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlotting ACF and PACF for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[43mplot_acf_pacf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Based on the ACF and PACF plots, set p, d, q (you might need to adjust these values based on your observations)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m p, d, q \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Example parameters, these should be adjusted based on the ACF/PACF plots\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m, in \u001b[0;36mplot_acf_pacf\u001b[0;34m(ticker, column_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m pacf_vals \u001b[38;5;241m=\u001b[39m pacf(stock_data[column_name], nlags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ACF plot\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43macf_vals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macf_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_line_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACF for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLag\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CollegeStuff/MahindraUniversity/4 - 1/ComputationalSequenceModelling/Assigments/csmass_env/lib/python3.12/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "\u001b[0;31mTypeError\u001b[0m: Axes.stem() got an unexpected keyword argument 'use_line_collection'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import os\n",
    "\n",
    "# Define the folder where the stationary data is stored\n",
    "output_folder = \"datasets\"\n",
    "tickers = ['IBM', 'AAPL', 'META', 'GOOGL']\n",
    "\n",
    "# Load the stationary data and plot ACF/PACF\n",
    "def plot_acf_pacf(ticker, column_name):\n",
    "    file_path = os.path.join(output_folder, f'{ticker}_stock_stationary.csv')\n",
    "    stock_data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # Drop any NaN values from the column\n",
    "    stock_data[column_name] = stock_data[column_name].dropna()\n",
    "    \n",
    "    # Plot ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    acf_vals = acf(stock_data[column_name], nlags=40)\n",
    "    pacf_vals = pacf(stock_data[column_name], nlags=40)\n",
    "    \n",
    "    # ACF plot\n",
    "    axes[0].stem(range(len(acf_vals)), acf_vals, use_line_collection=True)\n",
    "    axes[0].set_title(f\"ACF for {ticker} - {column_name}\")\n",
    "    axes[0].set_xlabel('Lag')\n",
    "    axes[0].set_ylabel('ACF')\n",
    "    \n",
    "    # PACF plot\n",
    "    axes[1].stem(range(len(pacf_vals)), pacf_vals, use_line_collection=True)\n",
    "    axes[1].set_title(f\"PACF for {ticker} - {column_name}\")\n",
    "    axes[1].set_xlabel('Lag')\n",
    "    axes[1].set_ylabel('PACF')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to train ARIMA model\n",
    "def train_arima_model(ticker, column_name, p, d, q):\n",
    "    file_path = os.path.join(output_folder, f'{ticker}_stock_stationary.csv')\n",
    "    stock_data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "    \n",
    "    # Drop any NaN values from the column\n",
    "    stock_data[column_name] = stock_data[column_name].dropna()\n",
    "    \n",
    "    # Build ARIMA model\n",
    "    model = ARIMA(stock_data[column_name], order=(p, d, q))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Print the model summary\n",
    "    print(f\"\\nARIMA Model Summary for {ticker} - {column_name}:\")\n",
    "    print(model_fit.summary())\n",
    "\n",
    "    return model_fit\n",
    "\n",
    "# Loop through tickers and apply the steps\n",
    "for ticker in tickers:\n",
    "    column_name = f'log_close_{ticker.lower()}'  # Using the 'log_close' column for ARIMA\n",
    "    \n",
    "    # Plot ACF and PACF to identify parameters\n",
    "    print(f\"\\nPlotting ACF and PACF for {ticker}...\")\n",
    "    plot_acf_pacf(ticker, column_name)\n",
    "    \n",
    "    # Based on the ACF and PACF plots, set p, d, q (you might need to adjust these values based on your observations)\n",
    "    p, d, q = 1, 1, 1  # Example parameters, these should be adjusted based on the ACF/PACF plots\n",
    "    \n",
    "    # Train ARIMA model\n",
    "    print(f\"\\nTraining ARIMA model for {ticker} - {column_name}...\")\n",
    "    arima_model = train_arima_model(ticker, column_name, p, d, q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96c614-199b-4230-ad59-442b2f26a7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
